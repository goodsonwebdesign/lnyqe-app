name: LNYQE CI/CD Pipeline with HTTPS Support

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]

jobs:
  build-and-test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0  # Get all history to ensure we have latest changes

    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '20'
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Test
      run: npm run ci:test

    - name: Build
      run: npm run ci:build

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: dist
        path: dist/

  build-docker-images:
    needs: build-and-test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    outputs:
      TIMESTAMP: ${{ env.TIMESTAMP }}

    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0  # Get all history to ensure we have latest changes

    # Download the build artifacts from the previous job
    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: dist
        path: dist

    - name: Display structure of downloaded files
      run: ls -R
      working-directory: dist

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWSACCESSKEYID }}
        aws-secret-access-key: ${{ secrets.AWSSECRETACCESSKEY }}
        aws-region: ${{ secrets.AWSREGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
      with:
        mask-password: true

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Generate unique deployment ID and build info
      id: build-info
      run: |
        TIMESTAMP=$(date +%Y%m%d%H%M%S)
        BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
        DEPLOY_ID="HTTPS-${{ github.run_id }}-${TIMESTAMP}"
        
        echo "BUILD_DATE=${BUILD_DATE}" >> $GITHUB_ENV
        echo "DEPLOY_ID=${DEPLOY_ID}" >> $GITHUB_ENV
        echo "TIMESTAMP=${TIMESTAMP}" >> $GITHUB_ENV
        echo "TIMESTAMP=${TIMESTAMP}" >> $GITHUB_OUTPUT
        
        echo "Creating build-info.txt file"
        echo "Build date: ${BUILD_DATE}" > build-info.txt
        echo "Deploy ID: ${DEPLOY_ID}" >> build-info.txt
        echo "Commit: ${{ github.sha }}" >> build-info.txt
        echo "Branch: ${{ github.ref_name }}" >> build-info.txt
        echo "Workflow Run: ${{ github.run_id }}" >> build-info.txt
        echo "HTTPS Enabled: Yes" >> build-info.txt

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile.prod
        push: true
        build-args: |
          BUILD_DATE=${{ env.BUILD_DATE }}
          DEPLOY_ID=${{ env.DEPLOY_ID }}
        tags: |
          ${{ steps.login-ecr.outputs.registry }}/${{ secrets.ECRREPOSITORY }}:latest
          ${{ steps.login-ecr.outputs.registry }}/${{ secrets.ECRREPOSITORY }}:${{ github.sha }}
          ${{ steps.login-ecr.outputs.registry }}/${{ secrets.ECRREPOSITORY }}:${{ github.sha }}-${{ env.TIMESTAMP }}

  deploy-to-aws:
    needs: build-docker-images
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'

    steps:
    - uses: actions/checkout@v3
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWSACCESSKEYID }}
        aws-secret-access-key: ${{ secrets.AWSSECRETACCESSKEY }}
        aws-region: ${{ secrets.AWSREGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
      with:
        mask-password: true

    # Create CloudWatch log group if it doesn't exist
    - name: Create CloudWatch log group
      id: create-log-group
      run: |
        echo "Creating CloudWatch log group for ECS logs if it doesn't exist..."

        # First, extract the cluster name to create appropriate log group
        CLUSTER_NAME=$(aws ecs describe-clusters \
          --clusters ${{ secrets.ECSCLUSTER }} \
          --query 'clusters[0].clusterName' \
          --output text)

        # Create log group if it doesn't exist
        LOG_GROUP_NAME="/ecs/$CLUSTER_NAME"
        echo "Checking for log group: $LOG_GROUP_NAME"

        # Try to describe the log group to check if it exists
        if ! aws logs describe-log-groups --log-group-name-prefix "$LOG_GROUP_NAME" | grep -q "$LOG_GROUP_NAME"; then
          echo "Log group doesn't exist. Creating it now..."
          aws logs create-log-group --log-group-name "$LOG_GROUP_NAME"

          # Set retention policy to 14 days to manage storage costs
          aws logs put-retention-policy --log-group-name "$LOG_GROUP_NAME" --retention-in-days 14

          echo "Log group created successfully!"
        else
          echo "Log group already exists."
        fi

        # Also create application-specific log group
        APP_LOG_GROUP_NAME="/ecs/lynqe-app"
        echo "Checking for application log group: $APP_LOG_GROUP_NAME"

        # Try to describe the app log group to check if it exists
        if ! aws logs describe-log-groups --log-group-name-prefix "$APP_LOG_GROUP_NAME" | grep -q "$APP_LOG_GROUP_NAME"; then
          echo "Application log group doesn't exist. Creating it now..."
          aws logs create-log-group --log-group-name "$APP_LOG_GROUP_NAME"

          # Set retention policy to 14 days to manage storage costs
          aws logs put-retention-policy --log-group-name "$APP_LOG_GROUP_NAME" --retention-in-days 14

          echo "Application log group created successfully!"
        else
          echo "Application log group already exists."
        fi

    # Register new task definition with specific image tag and deploy ID
    - name: Register new task definition
      id: register-task-def
      run: |
        # Get the current task definition
        echo "Retrieving current task definition..."
        TASK_DEF_ARN=$(aws ecs describe-services --cluster ${{ secrets.ECSCLUSTER }} --services ${{ secrets.ECSSERVICE }} --query 'services[0].taskDefinition' --output text --region ${{ secrets.AWSREGION }})
        aws ecs describe-task-definition --task-definition $TASK_DEF_ARN --region ${{ secrets.AWSREGION }} > task_def.json
        
        # Get the timestamp from previous job
        TIMESTAMP="${{ needs.build-docker-images.outputs.TIMESTAMP }}"
        if [ -z "$TIMESTAMP" ]; then
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
        fi
        
        # Create a unique deploy ID
        DEPLOY_ID="DEPLOY-${{ github.run_id }}-${TIMESTAMP}"
        echo "Using deploy ID: ${DEPLOY_ID}"
        
        # Define the specific image tag (not using latest)
        IMAGE_TAG="${{ github.sha }}-${TIMESTAMP}"
        ECR_REPOSITORY="${{ steps.login-ecr.outputs.registry }}.dkr.ecr.${{ secrets.AWSREGION }}.amazonaws.com/${{ secrets.ECRREPOSITORY }}"
        FULL_IMAGE="${ECR_REPOSITORY}:${IMAGE_TAG}"
        
        # If can't get specific tag, fall back to commit SHA
        if ! aws ecr describe-images --repository-name ${{ secrets.ECRREPOSITORY }} --image-ids imageTag=${IMAGE_TAG} --region ${{ secrets.AWSREGION }} &>/dev/null; then
          echo "Image with tag ${IMAGE_TAG} not found, falling back to commit SHA"
          FULL_IMAGE="${ECR_REPOSITORY}:${{ github.sha }}"
        fi
        
        # If still can't find, fall back to latest as last resort
        if ! aws ecr describe-images --repository-name ${{ secrets.ECRREPOSITORY }} --image-ids imageTag=${{ github.sha }} --region ${{ secrets.AWSREGION }} &>/dev/null; then
          echo "Image with tag ${{ github.sha }} not found, falling back to latest"
          FULL_IMAGE="${ECR_REPOSITORY}:latest"
        fi
        
        echo "Using image: ${FULL_IMAGE}"
        
        # Update the task definition with the new image and deploy ID
        echo "Updating task definition with new image and deploy ID..."
        NEW_TASK_DEF=$(cat task_def.json | jq --arg IMAGE "${FULL_IMAGE}" \
          --arg DEPLOY_ID "${DEPLOY_ID}" \
          '.taskDefinition | .containerDefinitions[0].image = $IMAGE | .containerDefinitions[0].environment += [{"name": "DEPLOY_ID", "value": $DEPLOY_ID}] | del(.taskDefinitionArn) | del(.revision) | del(.status) | del(.requiresAttributes) | del(.compatibilities) | del(.registeredAt) | del(.registeredBy)')
        
        # Register the new task definition
        echo "Registering new task definition..."
        NEW_TASK_ARN=$(aws ecs register-task-definition --cli-input-json "${NEW_TASK_DEF}" --region ${{ secrets.AWSREGION }} --query 'taskDefinition.taskDefinitionArn' --output text)
        
        echo "New task definition registered: ${NEW_TASK_ARN}"
        echo "task_arn=${NEW_TASK_ARN}" >> $GITHUB_ENV
        echo "deploy_id=${DEPLOY_ID}" >> $GITHUB_ENV

    # Check load balancer subnets to ensure compatibility with ECS service
    - name: Check load balancer configuration
      id: check-lb
      run: |
        echo "Checking load balancer configuration to ensure subnet compatibility..."

        # Get target group ARN from ECS service
        TARGET_GROUP_ARN=$(aws ecs describe-services \
          --cluster ${{ secrets.ECSCLUSTER }} \
          --services ${{ secrets.ECSSERVICE }} \
          --query 'services[0].loadBalancers[0].targetGroupArn' \
          --output text)

        echo "Target Group ARN: $TARGET_GROUP_ARN"

        # Get load balancer ARN from target group
        LOAD_BALANCER_ARN=$(aws elbv2 describe-target-groups \
          --target-group-arns $TARGET_GROUP_ARN \
          --query 'TargetGroups[0].LoadBalancerArns[0]' \
          --output text)

        echo "Load Balancer ARN: $LOAD_BALANCER_ARN"

        # Get availability zones and subnets used by the load balancer
        aws elbv2 describe-load-balancers \
          --load-balancer-arns $LOAD_BALANCER_ARN > lb_info.json

        LB_SUBNETS=$(jq -r '.LoadBalancers[0].AvailabilityZones[].SubnetId' lb_info.json)
        echo "Load balancer is using the following subnets:"
        echo "$LB_SUBNETS"

        # Format subnets for AWS CLI command
        SUBNET_CONFIG="["
        first=true
        for subnet in $LB_SUBNETS; do
          if [ "$first" = true ]; then
            SUBNET_CONFIG="${SUBNET_CONFIG}'${subnet}'"
            first=false
          else
            SUBNET_CONFIG="${SUBNET_CONFIG},'${subnet}'"
          fi
        done
        SUBNET_CONFIG="${SUBNET_CONFIG}]"

        echo "Formatted subnet configuration: $SUBNET_CONFIG"
        echo "subnet_config=$SUBNET_CONFIG" >> $GITHUB_ENV

    # Check ECS service configuration
    - name: Check ECS service status
      id: check-service
      run: |
        echo "Checking current ECS service status..."
        aws ecs describe-services \
          --cluster ${{ secrets.ECSCLUSTER }} \
          --services ${{ secrets.ECSSERVICE }} > service_status.json

        # Check if service is already being deployed
        pending_count=$(jq '.services[0].deployments | length' service_status.json)
        if [ $pending_count -gt 1 ]; then
          echo "::warning::There is already a deployment in progress. Waiting before attempting new deployment."
          sleep 60
        fi

        # Check if the service has any events that might indicate issues
        echo "Recent service events:"
        jq -r '.services[0].events[:5][] | .message' service_status.json

        # Check if there are any issues with the VPC configuration
        echo "Network configuration:"
        jq '.services[0].networkConfiguration' service_status.json

        # Extract security groups to reuse
        SECURITY_GROUPS=$(jq -r '.services[0].networkConfiguration.awsvpcConfiguration.securityGroups | join(",")' service_status.json | sed "s/,/','/g")
        echo "security_groups=['$SECURITY_GROUPS']" >> $GITHUB_ENV

    # Update ECS service with retries and improved error handling
    - name: Update ECS service with force-new-deployment
      id: update-service
      run: |
        max_attempts=3
        attempt=1
        backoff_seconds=30

        # Use the correct subnets identified from the load balancer
        echo "Using subnet configuration: ${{ env.subnet_config }}"
        echo "Using security groups: ${{ env.security_groups }}"
        echo "Using task definition: ${{ env.task_arn }}"
        echo "Using deploy ID: ${{ env.deploy_id }}"

        while [ $attempt -le $max_attempts ]; do
          echo "Attempt $attempt of $max_attempts to update ECS service..."

          # Get target group ARN for load balancer configuration
          TARGET_GROUP_ARN=$(aws ecs describe-services \
            --cluster ${{ secrets.ECSCLUSTER }} \
            --services ${{ secrets.ECSSERVICE }} \
            --region ${{ secrets.AWSREGION }} \
            --query 'services[0].loadBalancers[0].targetGroupArn' \
            --output text)

          if [ -n "$TARGET_GROUP_ARN" ] && [ "$TARGET_GROUP_ARN" != "null" ]; then
            echo "Updating service with load balancer configuration..."
            
            if aws ecs update-service \
              --cluster ${{ secrets.ECSCLUSTER }} \
              --service ${{ secrets.ECSSERVICE }} \
              --task-definition ${{ env.task_arn }} \
              --load-balancers "targetGroupArn=${TARGET_GROUP_ARN},containerName=lynqe-app-container,containerPort=80" \
              --network-configuration "awsvpcConfiguration={subnets=${{ env.subnet_config }},securityGroups=${{ env.security_groups }},assignPublicIp=ENABLED}" \
              --force-new-deployment \
              --region ${{ secrets.AWSREGION }}; then
                echo "ECS service update initiated successfully!"
                break
            fi
          else
            echo "Updating service without load balancer configuration..."
            
            if aws ecs update-service \
              --cluster ${{ secrets.ECSCLUSTER }} \
              --service ${{ secrets.ECSSERVICE }} \
              --task-definition ${{ env.task_arn }} \
              --network-configuration "awsvpcConfiguration={subnets=${{ env.subnet_config }},securityGroups=${{ env.security_groups }},assignPublicIp=ENABLED}" \
              --force-new-deployment \
              --region ${{ secrets.AWSREGION }}; then
                echo "ECS service update initiated successfully!"
                break
            fi
          fi
          
          exit_code=$?
          echo "Update failed with exit code: $exit_code"

          if [ $attempt -lt $max_attempts ]; then
            echo "Waiting ${backoff_seconds} seconds before retry..."
            sleep $backoff_seconds
            backoff_seconds=$(( backoff_seconds * 2 ))
          else
            echo "::error::Failed to update ECS service after $max_attempts attempts."
            exit 1
          fi

          attempt=$((attempt + 1))
        done

    # Check for stopped tasks to diagnose the root cause
    - name: Check for stopped tasks
      id: check-stopped-tasks
      run: |
        echo "Checking for recently stopped tasks to diagnose issues..."
        STOPPED_TASKS=$(aws ecs list-tasks \
          --cluster ${{ secrets.ECSCLUSTER }} \
          --family $(aws ecs describe-services --cluster ${{ secrets.ECSCLUSTER }} --services ${{ secrets.ECSSERVICE }} | jq -r '.services[0].taskDefinition' | cut -d'/' -f2 | cut -d':' -f1) \
          --desired-status STOPPED \
          --output json)

        TASK_ARNS=$(echo $STOPPED_TASKS | jq -r '.taskArns[]')

        if [ -n "$TASK_ARNS" ]; then
          echo "Found stopped tasks. Checking reason for failure..."
          aws ecs describe-tasks \
            --cluster ${{ secrets.ECSCLUSTER }} \
            --tasks $TASK_ARNS > stopped_tasks.json

          # Display the task stop reason
          echo "Task stop reasons:"
          jq -r '.tasks[] | .stoppedReason' stopped_tasks.json

          # Display container stop reason
          echo "Container stop details:"
          jq -r '.tasks[] | .containers[] | {name: .name, reason: .reason, exitCode: .exitCode}' stopped_tasks.json
        else
          echo "No stopped tasks found."
        fi

    # Wait for service to stabilize
    - name: Wait for ECS service to stabilize
      id: wait-for-service
      run: |
        echo "Waiting for ECS service to stabilize..."
        MAX_WAIT_TIME=300  # 5 minutes
        INTERVAL=15
        total_time=0

        while [ $total_time -lt $MAX_WAIT_TIME ]; do
          # Check deployment status
          DEPLOYMENT_STATUS=$(aws ecs describe-services \
            --cluster ${{ secrets.ECSCLUSTER }} \
            --services ${{ secrets.ECSSERVICE }} \
            --query 'services[0].deployments[0].status' \
            --output text)
          
          RUNNING_COUNT=$(aws ecs describe-services \
            --cluster ${{ secrets.ECSCLUSTER }} \
            --services ${{ secrets.ECSSERVICE }} \
            --query 'services[0].deployments[0].runningCount' \
            --output text)
          
          DESIRED_COUNT=$(aws ecs describe-services \
            --cluster ${{ secrets.ECSCLUSTER }} \
            --services ${{ secrets.ECSSERVICE }} \
            --query 'services[0].deployments[0].desiredCount' \
            --output text)
          
          echo "Deployment status: $DEPLOYMENT_STATUS, Running: $RUNNING_COUNT/$DESIRED_COUNT"
          
          if [ "$RUNNING_COUNT" -eq "$DESIRED_COUNT" ]; then
            echo "Service stabilized! All tasks are running."
            break
          fi
          
          echo "Waiting for ${INTERVAL} seconds..."
          sleep $INTERVAL
          total_time=$((total_time + INTERVAL))
        done

        if [ $total_time -ge $MAX_WAIT_TIME ]; then
          echo "::warning::Service did not fully stabilize within wait period, but deployment may still be in progress."
        fi

    # Get ALB endpoint for the deployed service
    - name: Get ALB endpoint
      id: get-endpoint
      run: |
        echo "Getting ALB endpoint for the deployed service..."
        # Get target group ARN from ECS service
        TARGET_GROUP_ARN=$(aws ecs describe-services \
          --cluster ${{ secrets.ECSCLUSTER }} \
          --services ${{ secrets.ECSSERVICE }} \
          --query 'services[0].loadBalancers[0].targetGroupArn' \
          --output text)

        if [ -n "$TARGET_GROUP_ARN" ] && [ "$TARGET_GROUP_ARN" != "null" ]; then
          # Get load balancer ARN from target group
          LOAD_BALANCER_ARN=$(aws elbv2 describe-target-groups \
            --target-group-arns $TARGET_GROUP_ARN \
            --query 'TargetGroups[0].LoadBalancerArns[0]' \
            --output text)

          # Get DNS name from load balancer
          ALB_DNS=$(aws elbv2 describe-load-balancers \
            --load-balancer-arns $LOAD_BALANCER_ARN \
            --query 'LoadBalancers[0].DNSName' \
            --output text)

          echo "Application is accessible at: http://${ALB_DNS}"
          echo "For HTTPS, the URL would be: https://${ALB_DNS}"
          echo "endpoint=https://${ALB_DNS}" >> $GITHUB_ENV
        else
          echo "No load balancer configuration found for this service."
        fi

    - name: Deployment summary
      run: |
        echo "::notice::Deployment completed successfully!"
        echo "::notice::Deployment ID: ${{ env.deploy_id }}"
        if [ -n "${{ env.endpoint }}" ]; then
          echo "::notice::Application is accessible at: ${{ env.endpoint }}"
        fi
        echo "::notice::Task Definition: ${{ env.task_arn }}"
